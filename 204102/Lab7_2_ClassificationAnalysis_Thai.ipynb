{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx8Q19d7BYyx"
      },
      "source": [
        "## ตัวอย่างการจำแนกความรู้สึกที่แสดงออกทางข้อความภาษาไทย \n",
        "(Thai Sentiment Analysis based on Classification Concept)  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ติดตั้ง Library สำหรับจัดการข้อมูลประเภทข้อความภาษาไทย"
      ],
      "metadata": {
        "id": "GQWGlVzxQ00d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # install library for Thai NLP\n",
        "!pip install pandas matplotlib pythainlp"
      ],
      "metadata": {
        "id": "K91X0m2uCilI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from pythainlp import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords"
      ],
      "metadata": {
        "id": "NK9AwNpugb0A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ขอสิทธิ์การเข้าใช้งาน Colab Notebook ซึ่งเก็บฟอนต์ภาษาไทยที่ใช้แสดงผลไว้**"
      ],
      "metadata": {
        "id": "3oE0d5tuu2RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "hZ683GW_mc68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "อ่านข้อมูลจากไฟล์ตัวอย่างที่เก็บไว้ใน Github"
      ],
      "metadata": {
        "id": "DzBiBg8VEP5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('https://github.com/PyThaiNLP/thai-sentiment-analysis-dataset/raw/master/review_shopping.csv',sep='\\t', names=['text', 'sentiment'], header=None )\n",
        "data.columns=['review','sentiment']\n",
        "print(data)"
      ],
      "metadata": {
        "id": "U0_QiYTkEUCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ทดสอบให้พิมพ์ stopword ภาษาไทย"
      ],
      "metadata": {
        "id": "3h5Vz-bEVppo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thai_stopwords = list(thai_stopwords())\n",
        "thai_stopwords"
      ],
      "metadata": {
        "id": "GR2xPLOVhO1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing  สร้างเป็นฟังก์ชันเพื่อเรียกใช้ซ้ำ"
      ],
      "metadata": {
        "id": "4KCPtUeBp6Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(cleaned_data):\n",
        "    # กำจัด URL\n",
        "    cleaned_data = \" \".join(re.sub(r\"https?://[A-Za-z0-9./]+\", '', w ) for w in cleaned_data.split())\n",
        "\n",
        "       # กำจัด stop words\n",
        "    cleaned_data = \" \".join(w for w in word_tokenize(cleaned_data) if w not in thai_stopwords)\n",
        "\n",
        "    # ตัดเครื่องหมายวรรคตอน ... remove punctuation\n",
        "    cleaned_data =  \" \".join([w for w in cleaned_data.split() if w not in list(string.punctuation)])\n",
        "\n",
        "    # กำจัดตัวเลข\n",
        "    cleaned_data = \" \".join(re.sub(r\"[0-9.]+%\", '', w ) for w in cleaned_data.split()) \n",
        "\n",
        "    # กำจัดข้อความภาษาอังกฤษ\n",
        "    cleaned_data = \" \".join(re.sub(r\"[A-Za-z]+\", '', w ) for w in cleaned_data.split()) \n",
        "\n",
        "    return cleaned_data\n"
      ],
      "metadata": {
        "id": "175PPFTogaF_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เรียกใช้งานฟังก์ชัน data_preprocessing"
      ],
      "metadata": {
        "id": "AyHAxKSuqEdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['review'] = data['review'].apply(data_preprocessing)\n",
        "# แสดงผลข้อมูลหลังจาก Data Preprocessing\n",
        "print(data)"
      ],
      "metadata": {
        "id": "vPBgczlrqGay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง Word Cloud สำหรับ Positive และ Negative รีวิว"
      ],
      "metadata": {
        "id": "aM1-rVJRjK_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "fp = 'THSarabunNew.ttf'"
      ],
      "metadata": {
        "id": "-_dXqClvkD-U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Cloud สำหรับ Positive รีวิว"
      ],
      "metadata": {
        "id": "OK3G7KUinbq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_positive = data[data['sentiment'] == 'pos']\n",
        "frequency_positive_dist = [ ]\n",
        "for message in data_positive['review']:\n",
        "       words = word_tokenize(message)\n",
        "       for w in words:\n",
        "              frequency_positive_dist.append(w)\n",
        "frequency_positive_dist = nltk.FreqDist(frequency_positive_dist)\n",
        "positive_wcloud = WordCloud( background_color = 'white', max_words=2000, height = 2000, width=4000, font_path=fp).generate_from_frequencies(frequency_positive_dist)\n",
        "\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.imshow(positive_wcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hkVfUOmbjLvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Cloud สำหรับ  Negative รีวิว"
      ],
      "metadata": {
        "id": "c6vAH9Ninktp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_negative = data[data['sentiment'] == 'neg']\n",
        "frequency_negative_dist = [ ]\n",
        "for message in data_negative['review']:\n",
        "       words = word_tokenize(message)\n",
        "       for w in words:\n",
        "              frequency_negative_dist.append(w)\n",
        "frequency_negative_dist = nltk.FreqDist(frequency_negative_dist)\n",
        "negative_wcloud = WordCloud(background_color = 'white', max_words=2000, height = 2000, width=4000,font_path=fp).generate_from_frequencies(frequency_negative_dist)\n",
        "\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.imshow(negative_wcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wU8YSl0Snmib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# สร้าง TF-IDF vectors"
      ],
      "metadata": {
        "id": "l3FIFZ9YCsMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y = encoder.fit_transform(data['sentiment'])\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "tfidf_vect.fit(data['review'])\n",
        "x_tfidf = tfidf_vect.transform(data['review'])\n"
      ],
      "metadata": {
        "id": "NH_bLKmgCsYR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "สร้าง Training และ Testing set"
      ],
      "metadata": {
        "id": "7OlmBpeHIcZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation\n",
        "from sklearn import model_selection\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(x_tfidf, y)\n"
      ],
      "metadata": {
        "id": "ydPsWmCsHcej"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Model building and evaluation\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "models = []\n",
        "models.append(('NB', MultinomialNB()))\n",
        "models.append(('Log-reg', LogisticRegression()))\n",
        "models.append(('SVC', SVC()))\n",
        "models.append(('RandomForest', RandomForestClassifier()))\n",
        "\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, clf in models:\n",
        "  model = clf\n",
        "  model.fit(X_train,y_train)\n",
        "  Predited_class = model.predict(X_test)\n",
        "  accuracy=accuracy_score(y_test, Predited_class)\n",
        "  results.append(accuracy)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f \" % (name, accuracy)\n",
        "  print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.bar(names,results)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OmlqGEKvIBdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply the best model"
      ],
      "metadata": {
        "id": "EswV0TgGeZ9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "8mrt50jZbSB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appication form for using sentiment analysis for English reviw based on data classifcaion concept model"
      ],
      "metadata": {
        "id": "rxOLZu8CdUHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter Review\n",
        "review = \" \\u0E40\\u0E22\\u0E35\\u0E48\\u0E22\\u0E21\\u0E21\\u0E32\\u0E01\" #@param {type:\"string\"}\n",
        "# use the classifier to predict the sentiment of given text\n",
        "review = data_preprocessing(review)\n",
        "xtest_tfidf = tfidf_vect.transform([review])\n",
        "result = model.predict(xtest_tfidf)\n",
        "result = encoder.inverse_transform(result)\n",
        "if result[0] == 'pos':\n",
        "      print(\"\\U0001F600\")\n",
        "else :\n",
        "      print(\"\\U0001F612\")\n"
      ],
      "metadata": {
        "id": "yt4381h3bbla"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}